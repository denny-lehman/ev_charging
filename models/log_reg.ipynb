{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic regression model\n",
    "Goal is to make a model that can predict when spot 02 will be available\n",
    "\n",
    "1st model, assume each time point is independent\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84c030c26aee9d09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0 imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4782fc2a5d6ccf9d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "if 'models' == os.getcwd().split('/')[-1]: os.chdir('..')\n",
    "if 'ev_charging' == os.getcwd().split('/')[-1]: print('in the right place!')\n",
    "else: os.chdir('/Users/varunvenkatesh/Documents/Github/ev_charging')\n",
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22fb8e3336ae7737"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.data_preprocessing import datetime_processing, userinput_processing, holiday_processing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, precision_score, recall_score, accuracy_score\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d3c2746d7b8a87b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 Data and Cleaning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d561042eae32d82d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cae6656692aeb3a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_of = pd.read_parquet('data/ACN-API/office001/').reset_index(drop=True)\n",
    "df_of = datetime_processing(df_of)\n",
    "df_of = userinput_processing(df_of)\n",
    "df_of = holiday_processing(df_of)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bc3a080bbc6076d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_of.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27c9099dc7a00dd3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_of.info()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19dd8e0aeadbccbb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 plotting and eval"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fd1517a24cbcc89"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_classification_plot(cm):\n",
    "    disp = ConfusionMatrixDisplay(cm)\n",
    "    disp = disp.plot(include_values=True, cmap='viridis', ax=None, xticks_rotation='horizontal')\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23577dbf759a1c93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_results(y_test, prediction):\n",
    "    cm = confusion_matrix(y_test,prediction)\n",
    "    make_classification_plot(cm)\n",
    "    \n",
    "    results = {'tpr': cm[1, 1]/np.sum(cm[1]),\n",
    "               'fpr': cm[0,1]/np.sum(cm[0]),\n",
    "               'accuracy': accuracy_score(y_test, prediction),\n",
    "               'precision': precision_score(y_test, prediction),\n",
    "               'recall': recall_score(y_test, prediction),\n",
    "        'f1':f1_score(y_test,prediction)}\n",
    "    return results\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c9ba2ce14ee28a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = {}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b84972c27f9c0d21"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 Make X and y values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "212245d109773fb7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp = df_of.copy().set_index('connectionTime')\n",
    "tmp = tmp[tmp['spaceID'] == '02'].sort_index()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4dacd35e4747513"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: make better variable names ie start_ -> session_start_time\n",
    "y = pd.DataFrame(index=pd.date_range('2019-03-25','2021-09-12', inclusive='both', freq='h', tz=0),columns=['is_available','sessionID'])\n",
    "y['is_available'] = 1\n",
    "for i in range(len(tmp)):\n",
    "    start_ = tmp.index[i]\n",
    "    end_ = tmp.loc[start_,'disconnectTime'] \n",
    "    session_ = tmp.loc[start_,'sessionID']\n",
    "    # print(start_,'\\t', end_,'\\t', session_)\n",
    "    y.loc[start_:end_,['is_available','sessionID']] = 0, session_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bd44672916d0ee3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = y['is_available']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2170f2c724d45de9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = pd.DataFrame(index=pd.date_range('2019-03-25','2021-09-12', inclusive='both', freq='h', tz=0),columns=['dow','hour','month'])\n",
    "# X['dow'] = X.index.dt.hour\n",
    "X['dow'] = X.index.dayofweek\n",
    "X['hour'] = X.index.hour\n",
    "X['month'] = X.index.month\n",
    "X['connectionTime'] = X.index\n",
    "X = holiday_processing(X).drop(columns=['connectionTime'])\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "460da19ef084d6c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(f'charger spot #2 is available {np.round(y.is_available.mean()*100,3)}% of the time')\n",
    "print(f'charger spot #2 is available {np.round(y.mean()*100,3)}% of the time')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57aa459620800b43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.shape[0] == y.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1df7bca93d99eee8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4 model time"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2eafe29d26fa2d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## using a stratified train test split as often as possible\n",
    "https://www.investopedia.com/terms/stratified_random_sampling.asp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22d5c3ab78571759"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create hold out test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, stratify=y)\n",
    "print(f'the training data has an average availability of {np.round(y_train.mean()*100,3)}%')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6dac9150ac9056"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 Baselines"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82a31e1197bd54b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.10 Guess always available (baseline)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6637e190339687b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('guess always available and never available')\n",
    "results['always_available'] = get_results(y_test, [1] * len(y_test))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c99ea90ad33c5a70"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.11 Guess never available (baseline)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8080feefa3068d9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('guess never available') \n",
    "results['never_available'] = get_results(y_test, [0] * len(y_test))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f42bacd27a8ad7ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2 Sklearn logistic regression models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "693ddf8bdb5eb790"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.21 L2 penalty"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8428123169eb95cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "model = LogisticRegression(penalty='l2')\n",
    "pipe = Pipeline([\n",
    "    ('ohe', OneHotEncoder(sparse_output=False, handle_unknown='ignore', drop='first')),\n",
    "    ('lr', model),\n",
    "])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "cv_results = cross_validate(pipe, X_train, y_train, cv=skf)\n",
    "test_score = cv_results[\"test_score\"]\n",
    "print(\n",
    "    f\"The average accuracy is {test_score.mean():.3f} ± {test_score.std():.3f}\"\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "print(f'test accuracy is {pipe.score(X_test, y_test)}')\n",
    "\n",
    "results['sk_log_l2_skf'] = get_results(y_test, pred)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea52e8a17bcd4141"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(pipe, X_train, y_train, cv=skf)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b72c2262fd1bcae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# standard error for "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "531cddcaf5fb74f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/22381497/python-scikit-learn-linear-model-parameter-standard-error\n",
    "N = len(X_train)\n",
    "p = len(pipe[0].get_feature_names_out()) + 1  # plus one because LinearRegression adds an intercept term\n",
    "print('X shape :', N,p)\n",
    "X_with_intercept = np.empty(shape=(N, p), dtype='float')\n",
    "X_with_intercept[:, 0] = 1\n",
    "X_with_intercept[:, 1:p] = pipe[0].transform(X_train)# ohe.transform(X_train)\n",
    "beta_hat = np.linalg.inv(X_with_intercept.T @ X_with_intercept) @ X_with_intercept.T @ y_train.values\n",
    "coefs_intercept = np.concatenate((pipe[1].intercept_, pipe[1].coef_.reshape(-1)))\n",
    "col_names = ['intercept'] + list(pipe[:-1].get_feature_names_out())\n",
    "pd.DataFrame(data=np.concatenate([[coefs_intercept], [beta_hat]]),\n",
    "             columns=['intercept'] + list(pipe[:-1].get_feature_names_out())).T.reset_index().rename(columns={0:'estimation',1:'standard_error','index':'coefficient'})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "800cf48a0a2461c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/22381497/python-scikit-learn-linear-model-parameter-standard-error\n",
    "X_with_intercept = np.empty(shape=(N, p), dtype='float')\n",
    "X_with_intercept[:, 0] = 1\n",
    "X_with_intercept[:, 1:p] = pipe[0].transform(X_train)# ohe.transform(X_train)\n",
    "X_with_intercept\n",
    "beta_hat = np.linalg.inv(X_with_intercept.T @ X_with_intercept) @ X_with_intercept.T @ y_train.values\n",
    "print(beta_hat)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c51ba7d6b8133f0e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe[:-1].get_feature_names_out()\n",
    "pipe[1].coef_\n",
    "pd.DataFrame(data=np.concatenate([[coefs_intercept], [beta_hat]]),\n",
    "             columns=['intercept'] + list(pipe[:-1].get_feature_names_out())).T.reset_index().rename(columns={0:'estimation',1:'standard_error','index':'coefficient'})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3060b66f78338938"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.22 L1 penalty"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3d4c169f11d2641"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "pipe = Pipeline([\n",
    "    ('ohe', OneHotEncoder()),\n",
    "    ('lrl1', model),\n",
    "])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "cv_results = cross_validate(pipe, X_train, y_train, cv=skf)\n",
    "test_score = cv_results[\"test_score\"]\n",
    "print(\n",
    "    f\"The average accuracy is {test_score.mean():.3f} ± {test_score.std():.3f}\"\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "print(f'test accuracy is {pipe.score(X_test, y_test)}')\n",
    "\n",
    "results['sk_log_reg_l1_skf'] = get_results(y_test, pred)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e61c8276fab844"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(pipe[-1].coef_.shape)\n",
    "pipe[-1].n_features_in_\n",
    "pipe[-1].intercept_\n",
    "pipe[-1].classes_\n",
    "pd.DataFrame(pipe[-1].coef_, columns=pipe[:-1].get_feature_names_out()).T\n",
    "# ?pipe[-1]\n",
    "# pipe[:-1].get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd4551a30f94d31c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# A sample toy binary classification dataset\n",
    "# X, y = datasets.make_classification(n_classes=2, random_state=0)\n",
    "# svm = LinearSVC(dual=\"auto\", random_state=0)\n",
    "lr = LogisticRegression(penalty=\"l2\")\n",
    "def confusion_matrix_scorer(clf, X, y):\n",
    "     y_pred = clf.predict(X)\n",
    "     cm = confusion_matrix(y, y_pred)\n",
    "     return {'tn': cm[0, 0], 'fp': cm[0, 1],\n",
    "             'fn': cm[1, 0], 'tp': cm[1, 1]}\n",
    "cv_results = cross_validate(lr, X_train, y_train, cv=5,\n",
    "                            scoring=confusion_matrix_scorer)\n",
    "# Getting the test set true positive scores\n",
    "print(cv_results['test_tp'])\n",
    "# Getting the test set false negative scores\n",
    "print(cv_results['test_fn'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c5bc02f40819210"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.23 elastic net penalty"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8c4df6d891eeabe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TO DO: use gridsearch to find best l1 ratio"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ff3d0634e1a7c5a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.1)\n",
    "pipe = Pipeline([\n",
    "    ('ohe', OneHotEncoder()),\n",
    "    ('lrl1', model),\n",
    "])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "cv_results = cross_validate(pipe, X_train, y_train, cv=skf)\n",
    "test_score = cv_results[\"test_score\"]\n",
    "print(\n",
    "    f\"The average accuracy is {test_score.mean():.3f} ± {test_score.std():.3f}\"\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "print(f'test accuracy is {pipe.score(X_test, y_test)}')\n",
    "\n",
    "results['sk_log_elasticnet_skf'] = get_results(y_test, pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b93131c37011e46"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3 Sklearn Random Forrest Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b66e415a2586e5d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tree models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "pipe = Pipeline([\n",
    "    ('ohe', OneHotEncoder()),\n",
    "    ('rf', model),\n",
    "])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "cv_results = cross_validate(pipe, X_train, y_train, cv=skf)\n",
    "test_score = cv_results[\"test_score\"]\n",
    "print(\n",
    "    f\"The average accuracy is {test_score.mean():.3f} ± {test_score.std():.3f}\"\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "print(f'test accuracy is {pipe.score(X_test, y_test)}')\n",
    "\n",
    "results['sk_rf_classification_skf'] = get_results(y_test, pred)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0b53300e915f758"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4.4 stats model version"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2f8266e4484885c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! pip install statsmodels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de90e0de223ce588"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import statsmodels.api as sm \n",
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "ohe.fit(X[['dow']])\n",
    "ohe.transform(X[['dow']])\n",
    "pd.DataFrame(ohe.transform(X[['dow']]), columns=ohe.get_feature_names_out(), index=X.index)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15e9512e59e970f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "ohe.fit(X[['dow']])\n",
    "ohe.transform(X[['dow']])\n",
    "ohe.get_feature_names_out()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    pd.DataFrame(ohe.transform(X[['dow']]), columns=ohe.get_feature_names_out(), index=X.index), \n",
    "    y, \n",
    "    test_size=.2, \n",
    "    stratify=y)\n",
    "log_reg = sm.Logit(y_train, X_train).fit() "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c6fb870a0c7b5e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ohe.fit(X[['dow']])\n",
    "ohe.transform(X[['dow']])\n",
    "ohe.get_feature_names_out()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    pd.DataFrame(ohe.transform(X[['dow']]), columns=ohe.get_feature_names_out(), index=X.index),#.drop(columns=ohe.get_feature_names_out()[0:3]), \n",
    "    y, \n",
    "    test_size=.2, \n",
    "    stratify=y)\n",
    "log_reg = sm.Logit(y_train, X_train).fit() \n",
    "print(log_reg.summary())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f81f2c0d648a9e90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(log_reg.summary()) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91052e544c1aefd0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_hat = log_reg.predict(X_test)\n",
    "prediction = list(map(round, y_hat))\n",
    "# confusion matrix \n",
    "cm = confusion_matrix(y_test, prediction)  \n",
    "print (\"Confusion Matrix : \\n\", cm)  \n",
    "  \n",
    "# accuracy score of the model \n",
    "print('Test accuracy = ', accuracy_score(y_test, prediction))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67aa66dd54e724c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results['sm_log_reg_dow_skf'] = get_results(y_test, prediction)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "453d81b8d93b8b8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "ohe.fit(X[['hour']])\n",
    "ohe.transform(X[['hour']])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    pd.DataFrame(ohe.transform(X[['hour']]), columns=ohe.get_feature_names_out(), index=X.index), \n",
    "    y, \n",
    "    test_size=.2, \n",
    "    stratify=y)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(ohe.transform(X[['hour']]), columns=ohe.get_feature_names_out(), index=X.index), y['is_available'])\n",
    "log_reg = sm.Logit(y_train, X_train).fit() "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36d506e6546e8d48"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(log_reg.summary()) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5f17ae0a8f8878b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "yhat = log_reg.predict(X_test) \n",
    "prediction = list(map(round, yhat))\n",
    "results['sm_hour_sfk'] = get_results(y_test, prediction)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73e2184f4fc0ed35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67fbfa136031c8be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# not weekend, the log odds is 1.782\n",
    "# for the weekend, the log odds increases 2.3780, to 4.1606\n",
    "y_train[X_train.hour_18==True]\n",
    "# probability of ytrain\n",
    "print('for not 6 PM...')\n",
    "p_success = y_train[X_train.hour_18==False].mean()\n",
    "p_failure = 1- p_success\n",
    "odds = p_success/p_failure\n",
    "log_odds = np.log(odds)\n",
    "print(f'prob of success {p_success}\\nprob of failure {p_failure}\\nodds of success {odds}\\nlog odds of success {log_odds}')\n",
    "p_not6pm = p_success\n",
    "print('\\n\\nfor 6 PM,')\n",
    "p_success = y_train[X_train.hour_18==True].mean()\n",
    "p_failure = 1- p_success\n",
    "odds = p_success/p_failure\n",
    "log_odds = np.log(odds)\n",
    "print(f'prob of success {p_success}\\nprob of failure {p_failure}\\nodds of success {odds}\\nlog odds of success {log_odds}')\n",
    "print(f'\\n\\nthe probaility of availability changes from {p_success} to {p_not6pm}, a difference of {np.round((p_success-p_not6pm)/p_not6pm*100,3)}%')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45c4f96690ddd56"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, prediction))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a05c96c5b777495c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "ohe.fit(X[['month','hour']])\n",
    "ohe.transform(X[['month','hour']])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    pd.DataFrame(ohe.transform(X[['month','hour']]), columns=ohe.get_feature_names_out(), index=X.index), \n",
    "    y, \n",
    "    test_size=.2, \n",
    "    stratify=y)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(ohe.transform(X[['hour']]), columns=ohe.get_feature_names_out(), index=X.index), y['is_available'])\n",
    "log_reg = sm.Logit(y_train, X_train).fit() "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75add6aeb107e0af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(log_reg.summary())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44d7cdcf69f97096"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "yhat = log_reg.predict(X_test) \n",
    "prediction = list(map(round, yhat))\n",
    "results['sm_month_hour_skf'] = get_results(y_test, prediction)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "154bcab58e367f3d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "ohe.fit(X)\n",
    "ohe.transform(X)\n",
    "ohe.get_feature_names_out()[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    pd.DataFrame(ohe.transform(X), columns=ohe.get_feature_names_out(), index=X.index), #.drop(columns=ohe.get_feature_names_out()[0]), \n",
    "    y, \n",
    "    test_size=.2, \n",
    "    stratify=y)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(ohe.transform(X[['hour']]), columns=ohe.get_feature_names_out(), index=X.index), y['is_available'])\n",
    "log_reg = sm.Logit(y_train, X_train).fit() \n",
    "print(log_reg.summary())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "487e95a76ffc0c36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "yhat = log_reg.predict(X_test) \n",
    "prediction = list(map(round, yhat))\n",
    "results['sm_month_hour_dow_skf'] = get_results(y_test, prediction)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c870ee46cee41bca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('guess always available and never available')\n",
    "results['always_available'] =  get_results(y_test, [1]*len(y_test))\n",
    "results['never_available'] =  get_results(y_test, [0]*len(y_test))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db05ddf85c8e8210"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "ohe.fit(X[['month']])\n",
    "ohe.transform(X[['month']])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    pd.DataFrame(ohe.transform(X[['month']]), columns=ohe.get_feature_names_out(), index=X.index), \n",
    "    y, \n",
    "    test_size=.2, \n",
    "    stratify=y)\n",
    "log_reg = sm.Logit(y_train, X_train).fit() "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95bebb19fd886989"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(log_reg.summary())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e0d1d8ba7de40aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "yhat = log_reg.predict(X_test) \n",
    "prediction = list(map(round, yhat))\n",
    "yhat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69a990e8be57b095"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(y_test, prediction))\n",
    "confusion_matrix(y_test, prediction)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94986115e5963f3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import  f1_score, precision_score, recall_score\n",
    "print(f'Precision: out of all the times the model predicted the charger would be available, {np.round(precision_score(y_test, prediction)*100,3)}% of the time it actually was available')\n",
    "print(f'Recall: out of all the times the charger was available, the model predicted the outcome correctly for {np.round(recall_score(y_test, prediction)*100,3)}% of those times')\n",
    "print(f'F1 score: the precision recall balance of the model was {np.round(f1_score(y_test,prediction),3)}')\n",
    "print(f'support available:   {np.sum(y_test==1)}')\n",
    "print(f'support unavailable: {np.sum(y_test==0)}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "991143d46bad2153"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(results).T"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39060099891284f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "60b1f761ad50d958"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Interpreting model coefficients"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b042a2451de495c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# probability of ytrain\n",
    "p_success = y_train.mean()\n",
    "p_failure = 1- p_success\n",
    "odds = p_success/p_failure\n",
    "log_odds = np.log(odds)\n",
    "print(f'prob of success {p_success}\\nprob of failure {p_failure}\\nodds of success {odds}\\nlog odds of success {log_odds}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "faeb1ad223a2111a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dummy_1 = pd.DataFrame([1]*len(y_train), columns=['intercept'], index=y_train.index)\n",
    "int_model = sm.Logit(y_train, dummy_1).fit()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d18429346aa626a4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(int_model.summary())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d1100bb9f6c9445"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'the model intercept term is {int_model.params.iloc[0]} which is the same as the log odds of the training set {log_odds}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b093841cd63ebd70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "61057e79e29614eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# new model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d58fa01891ec680"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X['is_weekend'] = X['dow'].isin([5,6])\n",
    "X"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e0ff064bd0b75ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "ohe.fit(X[['is_weekend']])\n",
    "ohe.transform(X[['is_weekend']])\n",
    "X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(ohe.transform(X[['is_weekend']]), columns=ohe.get_feature_names_out(), index=X.index), y)\n",
    "log_reg = sm.Logit(y_train, sm.add_constant(X_train)).fit() \n",
    "print(log_reg.summary())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53ab756536fa8a58"
  },
  {
   "cell_type": "markdown",
   "source": [
    "$logit(p/1-p) = \\beta_0 + \\beta_1*is_weekend$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc1500cad6a6d3c6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# not weekend, the log odds is 1.782\n",
    "# for the weekend, the log odds increases 2.3780, to 4.1606\n",
    "y_train[X_train.is_weekend_True==True]\n",
    "# probability of ytrain\n",
    "print('for weekdays...')\n",
    "p_success = y_train[X_train.is_weekend_True==False].mean()\n",
    "p_failure = 1- p_success\n",
    "odds = p_success/p_failure\n",
    "log_odds = np.log(odds)\n",
    "print(f'prob of success {p_success}\\nprob of failure {p_failure}\\nodds of success {odds}\\nlog odds of success {log_odds}')\n",
    "p_notweekend=p_success\n",
    "print('\\n\\nfor weekends,')\n",
    "p_success = y_train[X_train.is_weekend_True==True].mean()\n",
    "p_failure = 1- p_success\n",
    "odds = p_success/p_failure\n",
    "log_odds = np.log(odds)\n",
    "print(f'prob of success {p_success}\\nprob of failure {p_failure}\\nodds of success {odds}\\nlog odds of success {log_odds}')\n",
    "print(f'\\n\\nthe probaility of availability changes from {p_success} to {p_notweekend}, a difference of {np.round((p_success-p_notweekend)/p_notweekend*100,3)}%')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "975cc8439d19e307"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "?log_reg\n",
    "lowt = log_reg.params.iloc[0] + log_reg.params.iloc[1]\n",
    "lowf = log_reg.params.iloc[0]\n",
    "prwt = np.exp(lowt)/(1+np.exp(lowt))\n",
    "prwf = np.exp(lowf)/(1+np.exp(lowf))\n",
    "print(f'probability of weekend availability {prwt}\\nprobability of weekday availability {prwf}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56d7de501d3e7ef1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# weekend add 2.4 to the log odds of availability\n",
    "# p  exp(beta X)/ 1+ exp(beta X)\n",
    "# the weekend makes spot availability 2.4 times more likely to occur\n",
    "# the odds of is availability change by exp(2.49) time for c unit increase in x\n",
    "np.exp(2.493)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9a334ef13ccb04a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'the change in log odds of the day being a weekend is {2.493}')\n",
    "print(f'that means that the change in odds is {np.exp(2.493)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c17aa0bfcaf2b2a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "is_weekend = 0\n",
    "P_non_weekend = np.exp(1.7667 + 2.4931 * is_weekend)/(1+np.exp(1.7667 + 2.4931 * is_weekend))\n",
    "is_weekend = 1\n",
    "P_weekend = np.exp(1.7667 + 2.4931 * is_weekend)/(1+np.exp(1.7667 + 2.4931 * is_weekend))\n",
    "print(np.round(P_non_weekend,3), np.round(P_weekend, 3))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9b4d444c9ae77ae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6ebabfa62cad812c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.exp(5.2057)/(1+np.exp(5.2057))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc2b361a044f347e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a12e506833dad9a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
